# -*- coding: utf-8 -*-
"""amazon_product_web_scraping.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FFo2UeifBSgAsssL-srTuql04hokUCQK
"""

from bs4 import BeautifulSoup
import os
import random
import requests
import urllib

amazon_url = "https://www.amazon.com/s"
product_name = input("Enter product name: ")
desired_quantity = int(input("Enter desired quantity: "))
product_url_list = []
page_number = 1

payload = {
    "k": product_name,
    "page": 1
}
headers = {
    'authority': 'www.amazon.com',
    'method': 'GET',
    'scheme': 'https',
    'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
    'accept-encoding': 'gzip, deflate, br, zstd',
    'accept-language': 'en-US,en;q=0.9',
    'cache-control': 'max-age=0',
    'cookie': 'csm-sid=186-3980584-2379421; x-amz-captcha-1=1741130660765895; x-amz-captcha-2=6YZ4qY8UIPYguGC7asOiLg==; session-id=139-1852394-0257235; session-id-time=2082787201l; i18n-prefs=USD; sp-cdn="L5Z9:RW"; skin=noskin; ubid-main=130-1299393-7564566; session-token=qPoUk7UveE4GeTKaBynbBBT7Q3V4DDqhc41IZZEwyLNinU8zbj3UCsml8G5K7kqFy43jpV1f0YWCQlFp1V2e0wtgpHK3hQTvXrp49yUU/yBoCpiyfe0dkytcm1bLqUC6eeKQ2bAZkoL+s4xMKysAXzcmXVmZROxtdUTrzoejFBIau008cPZxzWQfDl2H0/17aKttAyd2taqzZyDA0E8YNe20OSnOxPBjaEpirxUPll/0kghoJ/29ZCrDxPYPXSMJ3u3SHYPEWVHEJRJEKwTEPTIaBHHeCqWqner/T9UWr4LYexaUaY3SbNYi6uELfbZu6JgNVCZT7ZiwHsSts70qFtfc9vBYP82I; csm-hit=tb:N15AS71APPWFH1Z2MPZ6+s-N15AS71APPWFH1Z2MPZ6|1741133468596&t:1741133468596&adb:adblk_no',
    'device-memory': '8',
    'downlink': '6.85',
    'dpr': '1.25',
    'ect': '4g',
    'priority': 'u=0, i',
    'referer': 'https://colab.research.google.com/',
    'rtt': '100',
    'sec-ch-device-memory': '8',
    'sec-ch-dpr': '1.25',
    'sec-ch-ua': '"Not(A:Brand";v="99", "Google Chrome";v="133", "Chromium";v="133"',
    'sec-ch-ua-mobile': '?0',
    'sec-ch-ua-platform': '"Windows"',
    'sec-ch-ua-platform-version': '"19.0.0"',
    'sec-ch-viewport-width': '1536',
    'sec-fetch-dest': 'document',
    'sec-fetch-mode': 'navigate',
    'sec-fetch-site': 'same-origin',
    'sec-fetch-user': '?1',
    'upgrade-insecure-requests': '1',
    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36',
    'viewport-width': '1536'
}

while len(product_url_list) < desired_quantity:
  payload = {
      "k": product_name,
      "page": page_number
  }
  response = requests.get(amazon_url, params=payload, headers=headers)
  soup = BeautifulSoup(response.text, "html.parser")
  image_tags = soup.find_all("img", {"class": "s-image"})
  for image_tag in image_tags:
    if len(product_url_list) >= desired_quantity:
      break
    product_url = image_tag["src"]
    product_url_list.append(product_url)
  page_number += 1


# fetching each image and downloading it to their respective folders
for product_url in product_url_list:
  product_folder = os.path.join("products", product_name)
  os.makedirs(product_folder, exist_ok=True)
  filename = os.path.basename(product_url)
  urllib.request.urlretrieve(product_url, os.path.join(product_folder, filename))